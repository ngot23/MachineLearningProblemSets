{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Weekly-Project-BBC Articles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngot23/MachineLearningProblemSets/blob/master/Week7_Project_BBC_Articles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8btHNo7H5Cf",
        "colab_type": "text"
      },
      "source": [
        "# Organize ML projects with Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yK9CuWlH5Ch",
        "colab_type": "text"
      },
      "source": [
        "While Machine Learning is powerful, people often overestimate it: apply machine learning to your project, and all your problems will be solved. In reality, it's not this simple. To be effective, one needs to organize the work very well. In this notebook, we will walkthrough practical aspects of a ML project. To look at the big picture, let's start with a checklist below. It should work reasonably well for most ML projects, but make sure to adapt it to your needs:\n",
        "\n",
        "1. **Define the scope of work and objective**\n",
        "    * How is your solution be used?\n",
        "    * How should performance be measured? Are there any contraints?\n",
        "    * How would the problem be solved manually?\n",
        "    * List the available assumptions, and verify if possible.\n",
        "    \n",
        "    \n",
        "2. **Get the data**\n",
        "    * Document where you can get that data\n",
        "    * Store data in a workspace you can easily access\n",
        "    * Convert the data to a format you can easily manipulate\n",
        "    * Check the overview (size, type, sample, description, statistics)\n",
        "    * Data cleaning\n",
        "    \n",
        "    \n",
        "3. **EDA & Data transformation**\n",
        "    * Study each attribute and its characteristics (missing values, type of distribution, usefulness)\n",
        "    * Visualize the data\n",
        "    * Study the correlations between attributes\n",
        "    * Feature selection, Feature Engineering, Feature scaling\n",
        "    * Write functions for all data transformations\n",
        "    \n",
        "    \n",
        "4. **Train models**\n",
        "    * Automate as much as possible\n",
        "    * Train promising models quickly using standard parameters. Measure and compare their performance\n",
        "    * Analyze the errors the models make\n",
        "    * Shortlist the top three of five most promising models, preferring models that make different types of errors.\n",
        "\n",
        "\n",
        "5. **Fine-tunning**\n",
        "    * Treat data transformation choices as hyperparameters, expecially when you are not sure about them (e.g., replace missing values with zeros or with the median value)\n",
        "    * Unless there are very few hyperparameter value to explore, prefer random search over grid search.\n",
        "    * Try ensemble methods\n",
        "    * Test your final model on the test set to estimate the generalizaiton error. Don't tweak your model again, you would start overfitting the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofeuKevOH5Ch",
        "colab_type": "text"
      },
      "source": [
        "## Example: Articles categorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2NSUqUEH5Ci",
        "colab_type": "text"
      },
      "source": [
        "### Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GttlMG-H5Cj",
        "colab_type": "text"
      },
      "source": [
        "Build a model to determine the categories of articles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwbjWOG1H5Ck",
        "colab_type": "text"
      },
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWq7xex_H5Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9W7Hzt2H5Cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbc = pd.read_csv('https://raw.githubusercontent.com/dhminh1024/practice_datasets/master/bbc-text.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teb1QvD1H5Cs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "79dba3ad-4723-4211-f79c-82fb32caf372"
      },
      "source": [
        "bbc.sample(20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>gallery unveils interactive tree a christmas t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1393</th>\n",
              "      <td>tech</td>\n",
              "      <td>viewers to be able to shape tv imagine editing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>politics</td>\n",
              "      <td>uk needs tax cuts  tories insist a major chang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2122</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>spider-man creator wins profits spider-man cre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>business</td>\n",
              "      <td>india s rupee hits five-year high india s rupe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>sport</td>\n",
              "      <td>almagro continues spanish surge unseeded nicol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>politics</td>\n",
              "      <td>ministers  naive  over phone-taps the governme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>politics</td>\n",
              "      <td>visa decision  every 11 minutes  visa processi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>tech</td>\n",
              "      <td>what price for  trusted pc security   you can ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1538</th>\n",
              "      <td>politics</td>\n",
              "      <td>no election tv debate  says blair tony blair h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>sport</td>\n",
              "      <td>can smith work scottish wonders  the worst kep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>sport</td>\n",
              "      <td>moya fights back for indian title carlos moya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864</th>\n",
              "      <td>tech</td>\n",
              "      <td>latest opera browser gets vocal net browser op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1767</th>\n",
              "      <td>sport</td>\n",
              "      <td>downing injury mars uefa victory middlesbrough...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>politics</td>\n",
              "      <td>taxes must be trusted - kennedy public trust i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>prince crowned  top music earner  prince earne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1309</th>\n",
              "      <td>sport</td>\n",
              "      <td>owen determined to stay in madrid england forw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1276</th>\n",
              "      <td>sport</td>\n",
              "      <td>henin-hardenne beaten on comeback justine heni...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           category                                               text\n",
              "633   entertainment  gallery unveils interactive tree a christmas t...\n",
              "1          business  worldcom boss  left books alone  former worldc...\n",
              "1393           tech  viewers to be able to shape tv imagine editing...\n",
              "660        politics  uk needs tax cuts  tories insist a major chang...\n",
              "2122  entertainment  spider-man creator wins profits spider-man cre...\n",
              "304        business  india s rupee hits five-year high india s rupe...\n",
              "185           sport  almagro continues spanish surge unseeded nicol...\n",
              "621        politics  ministers  naive  over phone-taps the governme...\n",
              "346        politics  visa decision  every 11 minutes  visa processi...\n",
              "1130           tech  what price for  trusted pc security   you can ...\n",
              "1538       politics  no election tv debate  says blair tony blair h...\n",
              "1424          sport  can smith work scottish wonders  the worst kep...\n",
              "25            sport  moya fights back for indian title carlos moya ...\n",
              "1864           tech  latest opera browser gets vocal net browser op...\n",
              "1767          sport  downing injury mars uefa victory middlesbrough...\n",
              "2108       politics  taxes must be trusted - kennedy public trust i...\n",
              "324   entertainment  dj double act revamp chart show dj duo jk and ...\n",
              "475   entertainment  prince crowned  top music earner  prince earne...\n",
              "1309          sport  owen determined to stay in madrid england forw...\n",
              "1276          sport  henin-hardenne beaten on comeback justine heni..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBW_Sg2RH5Cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "15d16740-b45b-4183-c0cb-bd70990517ca"
      },
      "source": [
        "bbc.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  2225 non-null   object\n",
            " 1   text      2225 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 34.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3VRY5Zxmw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "28f6de9c-81d3-4b7b-c2af-0ffb17259ff8"
      },
      "source": [
        "# Your code here\n",
        "bbc.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2225</td>\n",
              "      <td>2225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5</td>\n",
              "      <td>2126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>sport</td>\n",
              "      <td>blind student  hears in colour  a blind studen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>511</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       category                                               text\n",
              "count      2225                                               2225\n",
              "unique        5                                               2126\n",
              "top       sport  blind student  hears in colour  a blind studen...\n",
              "freq        511                                                  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK5UAOTardLj",
        "colab_type": "text"
      },
      "source": [
        "### PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUVCN5Wrrfie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c6d9657c-b5e7-433c-fd63-1a0b67d352e0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69oBhAOzri7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "vocab = Counter()\n",
        "for twit in bbc['text']:\n",
        "    for word in twit.split(' '):\n",
        "        vocab[word] += 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV6mzgi2rpQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "1250a627-21c8-4ed0-a493-5bd3b4ca42f0"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "vocab_reduced = Counter()\n",
        "# Go through all of the items of vocab using vocab.items() and pick only words that are not in 'stop_words' \n",
        "# and save them in vocab_reduced\n",
        "\n",
        "for w, c in vocab.items():\n",
        "    if not w in stop_words:\n",
        "        vocab_reduced[w]=c\n",
        "\n",
        "vocab_reduced.most_common(20)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 65553),\n",
              " ('said', 5072),\n",
              " ('-', 3195),\n",
              " ('mr', 2992),\n",
              " ('would', 2574),\n",
              " ('also', 2154),\n",
              " ('people', 1970),\n",
              " ('new', 1957),\n",
              " ('us', 1786),\n",
              " ('one', 1705),\n",
              " ('could', 1509),\n",
              " ('said.', 1499),\n",
              " ('year', 1396),\n",
              " ('last', 1380),\n",
              " ('first', 1277),\n",
              " ('.', 1171),\n",
              " ('two', 1161),\n",
              " ('government', 1085),\n",
              " ('world', 1076),\n",
              " ('uk', 993)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7KuaD70ry5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c79bcdee-7c23-476d-cfbc-9abbff9732ee"
      },
      "source": [
        "# Removing special characters and \"trash\"\n",
        "import re\n",
        "def preprocessor(text):\n",
        "    # Remove HTML markup\n",
        "    # text = None # Your code here\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "\n",
        "    # Save emoticons for later appending\n",
        "    # Your code here\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "\n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    # Your code here\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text\n",
        "\n",
        "print(preprocessor('., |||<><>'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oufjTxTr4nG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer and stemming\n",
        "# tokenizer: to break down our twits in individual words\n",
        "# stemming: reducing a word to its root\n",
        "from nltk.stem import PorterStemmer\n",
        "# Your code here\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yTLwesGs6BK",
        "colab_type": "text"
      },
      "source": [
        "### TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt5XVxWAtJYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = bbc['text']\n",
        "y = bbc['category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VIXEWUut0J7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Pipeline, OneVsRestClassifier, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop_words,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)\n",
        "\n",
        "clf = Pipeline([('vect', tfidf),\n",
        "                ('clf', OneVsRestClassifier(SVC()))])\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRFruxQXvJxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "11be0f52-2250-4c63-aa42-7ef582bb708a"
      },
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7f38300a9bf8>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                                 tokenizer=<function tokenizer_porter at 0x7f38300a9d90>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 OneVsRestClassifier(estimator=SVC(C=1.0, break_ties=False,\n",
              "                                                   cache_size=200,\n",
              "                                                   class_weight=None, coef0=0.0,\n",
              "                                                   decision_function_shape='ovr',\n",
              "                                                   degree=3, gamma='scale',\n",
              "                                                   kernel='rbf', max_iter=-1,\n",
              "                                                   probability=False,\n",
              "                                                   random_state=None,\n",
              "                                                   shrinking=True, tol=0.001,\n",
              "                                                   verbose=False),\n",
              "                                     n_jobs=None))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OR-AUvDwdvx",
        "colab_type": "text"
      },
      "source": [
        "### EVALUATE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol7rsn3Nwh0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "a986e169-a1f2-4529-d843-34c5e1036470"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "predictions = clf.predict(X_test)\n",
        "print('accuracy:',accuracy_score(y_test,predictions))\n",
        "print('confusion matrix:\\n',confusion_matrix(y_test,predictions))\n",
        "print('classification report:\\n',classification_report(y_test,predictions))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9842696629213483\n",
            "confusion matrix:\n",
            " [[88  1  1  0  0]\n",
            " [ 0 92  0  0  0]\n",
            " [ 1  1 82  1  0]\n",
            " [ 1  0  0 98  0]\n",
            " [ 0  0  1  0 78]]\n",
            "classification report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     business       0.98      0.98      0.98        90\n",
            "entertainment       0.98      1.00      0.99        92\n",
            "     politics       0.98      0.96      0.97        85\n",
            "        sport       0.99      0.99      0.99        99\n",
            "         tech       1.00      0.99      0.99        79\n",
            "\n",
            "     accuracy                           0.98       445\n",
            "    macro avg       0.98      0.98      0.98       445\n",
            " weighted avg       0.98      0.98      0.98       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}